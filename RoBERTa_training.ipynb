{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc83cd7-a896-4104-a6e7-c45ce6a7216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import RobertaTokenizerFast, RobertaConfig, RobertaForMaskedLM\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c9c14-9558-423f-b493-a122cd941e12",
   "metadata": {},
   "source": [
    "### BPE-токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196352d8-32e2-4ff2-8604-1e47497c0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\m092\\avar_bert\\raw_corpora'\n",
    "paths = [path + '\\\\' + fn for fn in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9eae16-3c76-4cfc-b8c0-02b9681a9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(files=paths, vocab_size=50265, min_frequency=2,\n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006108c7-f31f-4d07-9b49-91d4c9af7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./avarBPEtokenizer') # для проверки эпохи копировать файлы из папки avarBPEtokenizer в файл с моделью\n",
    "tokenizer.save_model('avarBPEtokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53acbb-d3dc-4378-9dab-69908859ea45",
   "metadata": {},
   "source": [
    "### MLM (обучение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1421ec7-e141-4376-9e06-22139c2942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm(tensor):\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    mask_arr = (rand < 0.15) * (tensor > 2)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        tensor[i, selection] = 4\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6f172-e835-4d22-b75b-c8030b56f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d3dcd-2766-43e8-86d8-79fbdb20b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('avarCorpora.json', 'r', encoding='utf-8') as f:\n",
    "    corpora = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240a9fe-73cc-463e-8ff8-4ffba62612f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "mask = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05080cdd-f307-4bfe-8d86-5d1555b88ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avar_tokenizer = RobertaTokenizerFast.from_pretrained('avarBPEtokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce107f5-7d34-4136-85d1-425d2a14f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = avar_tokenizer(corpora, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "labels.append(sample.input_ids)\n",
    "mask.append(sample.attention_mask)\n",
    "input_ids.append(mlm(sample.input_ids.detach().clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754d4cb-a5dc-460a-80da-d3769d1d275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids)\n",
    "mask = torch.cat(mask)\n",
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2cb90-8884-44fa-bb6c-c50da4d36e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset({'input_ids': input_ids, 'attention_mask': mask, 'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a09384-98f4-42fd-b977-8a2e08d79915",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af581cd-72e0-45ef-92ca-b54755e3ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig(\n",
    "    vocab_size=50265,\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")\n",
    "model = RobertaForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58b8d1-0571-450b-8fb6-40427c199c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a019da3-9f0a-4d99-8b09-6f59553549aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab2a30-c56d-40bf-98dc-20382dc33d41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# несколько эпох подряд\n",
    "# for epoch in range(1, 6):\n",
    "#     loop = tqdm(loader, leave=True)\n",
    "#     for batch in loop:\n",
    "#         optim.zero_grad()\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask,\n",
    "#                         labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#         loop.set_description(f'Epoch {epoch}')\n",
    "        # loop.set_postfix(loss=loss.item())\n",
    "    # model.save_pretrained(f'./avarBERT-{epoch}_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47907a06-b5ad-4223-bc52-16bab243f3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# одна эпоха\n",
    "epoch = 1\n",
    "loop = tqdm(loader, leave=True)\n",
    "for batch in loop:\n",
    "    optim.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                    labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    loop.set_description(f'Epoch {epoch}')\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "model.save_pretrained(f'./avarBERT-{epoch}_epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
