{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aab7d8f-9b00-4a29-968b-84cce8e0c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасеты\n",
    "from datasets import load_dataset\n",
    "# время обработки задач\n",
    "from tqdm.auto import tqdm\n",
    "# пути в операционке (заменить на OS)\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1b66e9-c1bd-40f9-9c54-4babedaebbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1d4fc460094069b1e224393fed2aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436c9ed6f36c499e8d3fab8221126a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b2bf9612354a05b5e4de0881f57440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/531M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66914bffbfa54acda4257339de93f398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/533M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f346a599b46846aaa43fb5b655728bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/533M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27960042e0ae426fa3e204ffc983be79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479bc962ffe47adbd49e97d0f203106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/534M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09f17b954b54954819463378687e692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/533M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe220e8f5fb431e8fa5066801118223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/533M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c590bab96d410d8b2bc009bb3d3c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7de0122150f499ba6e057e6aaa8e85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/534M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a8c32b4f84c0a8d69adf22204fc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/534M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10bc11c2b764a31a63cd7e4b9cd4db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/535M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f70e2c8a20493aad50363a642d2d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cff868357d43cbaadf080909f7d648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451ce738064442fb849f7929f0734673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b1547829d418fa2bd9763e67ffc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6521169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m092\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('oscar', 'unshuffled_deduplicated_el')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29209bc9-2b19-42e4-935f-ac2d547de58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Πολλοί ιδιοκτήτες σκύλων θα ήθελαν να απολαύσουν την γυμναστική τους με το αγαπημένο τους κατοικίδιο. Οι πιο συνηθισμένοι τρόποι για να γίνει αυτό είναι ο περίπατος, το τρέξιμο η κάνοντας ποδήλατο με το σκυλάκι να τρέχει πίσω μας.\\nΩστόσο, ο κύριος Nic Bello ψάχνοντας κάτι πιο ξεκούραστο ξεκίνησε να διδάσκει το μικρό του φίλο “Pancho”, yoga. Το μικρό και ευερέθιστο Τσιουάουα όπως θα δείτε, όχι μόνο ανταποκρίνεται, δείχνει και να το διασκεδάζει. Σίγουρα μερικά τεντώματα και βαθιές εισπνοές θα το βοηθήσουν να χαλαρώσει.\\nΤο “ζευγάρι” έχει πλέον κυκλοφορήσει μια σειρά από doga βίντεο όπου παρουσιάζουν κάποιες πιο περίπλοκες κινήσεις.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][999]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6fdeee-9be6-44c1-a6db-780d91217702",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_path = './data/text/oscar_el/'\n",
    "os.makedirs(el_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dbe392-0c49-472e-8c05-447e8f427341",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "file_count = 0\n",
    "for sample in dataset[\"train\"]:\n",
    "    sample_text = sample['text'].replace('\\n', '')\n",
    "    text_data.append(sample_text)\n",
    "    \n",
    "    if len(text_data) == 10_000:\n",
    "        # Save tokens to a file every 10,000 samples\n",
    "        with open(os.path.join(el_path, f'text_{file_count}.txt'), 'w', encoding='utf-8') as file:\n",
    "            file.write('\\n'.join(text_data))\n",
    "        text_data = []\n",
    "        file_count += 1\n",
    "\n",
    "# че-то зачем-то ещё раз сохранили\n",
    "# Save any remaining tokens\n",
    "if text_data:\n",
    "    with open(os.path.join(el_path, f'text_{file_count}.txt'), 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "521d06b4-8928-48c7-b6d0-3183b34bb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14ea646-8703-48d5-8692-76458ef63fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранили тексты, молодцы, а вот пути до них:\n",
    "tokenization_files = [str(x) for x in Path('./data/text/oscar_el').glob('**/*.txt')]\n",
    "# tokenization_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268f3088-9480-4f1a-af07-3cbd524aa0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(files=tokenization_files[:200], vocab_size=30_522, min_frequency=2,\n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a624b9-44b3-498d-a6f8-857110a6d561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lil_el_model\\\\vocab.json', 'lil_el_model\\\\merges.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkdir('./lil_el_model')\n",
    "tokenizer.save_model('lil_el_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0851062-4b89-4d36-b09d-33a13e9d0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0f5d610-d2d1-4c5a-bdb5-3131132a2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и вот оно может работать, ура\n",
    "smart_tokenizer = RobertaTokenizerFast.from_pretrained('lil_el_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d018a24-d1b0-418f-a1e3-bf41cf795f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_phrase = \"Καλημερα\"\n",
    "# example_phrase = \"Η Γερμανία κατέληξε τελικά σε συμφωνία με την Ιταλία για την επιστροφή μεταναστών που είχαν ζητήσει άσυλο στη χώρα αυτή\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1838a4f-8589-4026-9072-a90ee42caec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 13571, 16578, 2], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smart_tokenizer(example_phrase, padding=\"max_length\", max_length=100)\n",
    "smart_tokenizer(example_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f829b-9941-4e4a-a232-5c8bf87e9558",
   "metadata": {},
   "source": [
    "Теперь обучим на полном датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12ba04-d278-4061-b216-6957bdb7717b",
   "metadata": {},
   "source": [
    "MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df1e5cb4-259e-40ff-b307-9316722c21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b29cd4d-709b-4f02-bc8b-afe9e96bcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm(tensor):\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    # mask_arr = (rand < 0.15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "    mask_arr = (rand < 0.15) * (tensor > 2)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        tensor[i, selection] = 4\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ce0b194-f577-46e9-9592-96198d4514d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization_files # всё ещё все файлы\n",
    "input_ids = []\n",
    "mask = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da404ccc-32c5-4158-bac1-2f5aad61a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5ef489949e4a93b6be6ed44d88f5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for path in tqdm(tokenization_files[:50]):\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        lines = file.read().split('\\n')\n",
    "    sample = smart_tokenizer(lines, max_length=512, padding='max_length', truncation=True, return_tensors='pt') # truncation=true обрезать слишком длинные строки\n",
    "    labels.append(sample.input_ids)\n",
    "    mask.append(sample.attention_mask)\n",
    "    input_ids.append(mlm(sample.input_ids.detach().clone())) # .detach().clone() — как deepcopy мы не хотим портить настоящий список с id, т. к. он нужен в labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28210068-34bc-4ba1-87a1-24c8572a4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # можно было и сразу нормально записывать, нет?..\n",
    "# input_ids = torch.cat(input_ids)\n",
    "# mask = torch.cat(mask)\n",
    "# labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e979352a-a393-438b-9650-ba1ae45d7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(tensor_name, 'tensor_file.pt') # можно схранить\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16875a24-9a6c-4c52-b0aa-5f4504c64df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        # store encodings internally\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of samples\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5358ccc3-66a5-4b7d-a017-7450ccad179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset({'input_ids': input_ids, 'attention_mask': mask, 'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e680b5b-44ec-4020-9a86-42da0bb802ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c6085-e341-44da-b173-01711999937c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f911b136-c67a-4fed-8d7d-3ef55aec3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=30_522,\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")\n",
    "model = RobertaForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba6401-c582-4e03-a063-10b6af294280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88616baa-b49f-4fd2-b060-134337772827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc1512b0-939c-4fb9-a0b6-d558b7d26f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m092\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4605425d-0732-43c2-a389-2f4aae940f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cfaec9-dcd8-4e54-bd7d-44fde93ff0d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# setup loop with TQDM and dataloader\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[43mloader\u001b[49m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# initialize calculated gradients (from prev step)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb78b72-a6f6-48ad-a5de-40f9f257fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./lil_el_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
